/usr/local/cuda
-------- params --------
corpus: FULL
device: gpu
numLayers: 2
numEpochs: 1
windowSize: 0
numNegPerPos: 7
batchSize: 128
shuffleTraining: f
embeddingsFile: /Users/christanner/research/DeepCoref/data/gloveEmbeddings.400.txt
hddcrpFullFile: /Users/christanner/research/DeepCoref/data/predict.WD.semeval.txt
dropout: 0.3
clusterMethod: avgavg
numFilters: 64
lemmaType: none
lemmaEmbeddingsFile: /Users/christanner/research/DeepCoref/data/lemmaEmbeddings.400.txt
------------------------
* loading HDDCRP's mention boundaries file:
	# hms by end of parsing, based on a per doc basis: 3109
	* parsed  3109 mentions
	* created  3109  hm_ids!
args: Namespace(batchSize=128, clusterMethod='avgavg', corpusPath='/Users/christanner/research/DeepCoref/data/ECB_FULL/', device='gpu', dropout=0.3, embeddingsBaseFile='', embeddingsFile='/Users/christanner/research/DeepCoref/data/gloveEmbeddings.400.txt', embeddingsType='type', featurePOS='none', filterMultiplier=1.0, hddcrpBaseFile='predict', hddcrpFullFile='/Users/christanner/research/DeepCoref/data/predict.WD.semeval.txt', lemmaBaseFile='400', lemmaEmbeddingsFile='/Users/christanner/research/DeepCoref/data/lemmaEmbeddings.400.txt', lemmaType='none', mentionsFile='/Users/christanner/research/DeepCoref/data/goldTruth_events.txt', numEpochs=1, numFilters=64, numLayers=2, numNegPerPos=7, posEmbeddingsFile='/Users/christanner/research/DeepCoref/data/posEmbeddings100.txt', posType='none', replacementsFile='/Users/christanner/research/DeepCoref/data/replacements.txt', resultsDir='/Users/christanner/research/DeepCoref/results/', shuffleTraining=False, stanOutputDir='/Users/christanner/research/DeepCoref/data/stanford_output/', stitchMentions=False, verbose=True, windowSize=0)
* parsing ECB corpus...done
* loading Stanford's Parsing data... done
we've successfully added stanford links to every single token within our 982 docs
self.args.featurePOS: none
self.args.lemmaType: none
args: Namespace(batchSize=128, clusterMethod='avgavg', corpusPath='/Users/christanner/research/DeepCoref/data/ECB_FULL/', device='gpu', dropout=0.3, embeddingsBaseFile='', embeddingsFile='/Users/christanner/research/DeepCoref/data/gloveEmbeddings.400.txt', embeddingsType='type', featurePOS='none', filterMultiplier=1.0, hddcrpBaseFile='predict', hddcrpFullFile='/Users/christanner/research/DeepCoref/data/predict.WD.semeval.txt', lemmaBaseFile='400', lemmaEmbeddingsFile='/Users/christanner/research/DeepCoref/data/lemmaEmbeddings.400.txt', lemmaType='none', mentionsFile='/Users/christanner/research/DeepCoref/data/goldTruth_events.txt', numEpochs=1, numFilters=64, numLayers=2, numNegPerPos=7, posEmbeddingsFile='/Users/christanner/research/DeepCoref/data/posEmbeddings100.txt', posType='none', replacementsFile='/Users/christanner/research/DeepCoref/data/replacements.txt', resultsDir='/Users/christanner/research/DeepCoref/results/', shuffleTraining=False, stanOutputDir='/Users/christanner/research/DeepCoref/data/stanford_output/', stitchMentions=False, verbose=True, windowSize=0)
tf version: 1.3.0
devices: [name: "/cpu:0"
device_type: "CPU"
memory_limit: 268435456
locality {
}
incarnation: 16221505251184627988
]
-----------------------
* in loadEmbeddings
* in constructECBTraining()
#pos: 2004
#neg: 14028
* in constructECBDev()
*** : 26_5ecbplus.xml has exactly 1 hmention
*** : 27_2ecb.xml has exactly 1 hmention
*** : 27_6ecb.xml has exactly 1 hmention
*** : 28_8ecb.xml has exactly 1 hmention
*** : 29_4ecb.xml has exactly 1 hmention
*** : 29_5ecb.xml has exactly 1 hmention
*** : 30_13ecb.xml has exactly 1 hmention
*** : 31_12ecb.xml has exactly 1 hmention
*** : 31_3ecbplus.xml has exactly 1 hmention
*** : 34_14ecb.xml has exactly 1 hmention
*** : 34_15ecb.xml has exactly 1 hmention
*** : 34_2ecb.xml has exactly 1 hmention
*** : 34_3ecb.xml has exactly 1 hmention
*** : 34_4ecb.xml has exactly 1 hmention
*** : 34_7ecb.xml has exactly 1 hmention
*** : 34_8ecb.xml has exactly 1 hmention
*** : 36_9ecb.xml has exactly 1 hmention
*** : 39_10ecb.xml has exactly 1 hmention
*** : 39_11ecb.xml has exactly 1 hmention
*** : 39_1ecb.xml has exactly 1 hmention
*** : 39_2ecb.xml has exactly 1 hmention
*** : 39_4ecb.xml has exactly 1 hmention
*** : 39_7ecb.xml has exactly 1 hmention
*** : 39_8ecb.xml has exactly 1 hmention
*** : 42_13ecb.xml has exactly 1 hmention
*** : 42_2ecb.xml has exactly 1 hmention
*** : 42_7ecb.xml has exactly 1 hmention
*** : 42_8ecb.xml has exactly 1 hmention
*** : 42_9ecb.xml has exactly 1 hmention
* training data shape: (16032, 2, 1, 400, 1)
* dev data shape: (1605, 2, 1, 400, 1)
* test data shape: (13017, 2, 1, 400, 1)
going deep!! 2 sections of convolution
____________________________________________________________________________________________________
Layer (type)                     Output Shape          Param #     Connected to                     
====================================================================================================
input_1 (InputLayer)             (None, 1, 400, 1)     0                                            
____________________________________________________________________________________________________
input_2 (InputLayer)             (None, 1, 400, 1)     0                                            
____________________________________________________________________________________________________
sequential_1 (Sequential)        (None, 64)            856576      input_1[0][0]                    
                                                                   input_2[0][0]                    
____________________________________________________________________________________________________
lambda_1 (Lambda)                (None, 1)             0           sequential_1[1][0]               
                                                                   sequential_1[2][0]               
====================================================================================================
Total params: 856,576
Trainable params: 856,576
Non-trainable params: 0
____________________________________________________________________________________________________
None
Train on 16032 samples, validate on 1605 samples
Epoch 1/1
  128/16032 [..............................] - ETA: 356s - loss: 0.8174  256/16032 [..............................] - ETA: 316s - loss: 0.7008  384/16032 [..............................] - ETA: 300s - loss: 0.5737  512/16032 [..............................] - ETA: 292s - loss: 0.4930  640/16032 [>.............................] - ETA: 285s - loss: 0.4319  768/16032 [>.............................] - ETA: 280s - loss: 0.3998  896/16032 [>.............................] - ETA: 277s - loss: 0.3710